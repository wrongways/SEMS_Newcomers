:icons: font

== Containers
Atos' offers two solutions for cluster management, SMC and SMC&nbsp;xScale. Both
use container technology. SMC uses podman, SMC&nbsp;xScale uses kubernetes. It
turns out that the distinction between the two has an unreasonably
largefootnote:[In my opinion] repercussion
on all sorts of things from the structure of the git repository and
ansible playbooks, to the documentation. It is therefore necessary to introduce
this material before looking in detail at the SEMS constituent parts. This
chapter introduces containers before looking at the specifics of podman and kubernetes.

Containers are a light-weight virtualization technology providing an isolated execution
environment for applications that run on Linux. They are an evolution of BSD&nbsp;Jails,
and *chroot* before thatfootnote:[IBM had workload partitions as a knee-jerk reaction to
Solaris' containers years before Linux containers and Docker
became a thing, but IBM never realized what a great feature they were and as a result
they were never fully developed ‚Äì a major missed opportunity].
A container has it's own namespace and applications
running inside a container have no visibility of other containers or the host OS.
The most common container environment is Docker, but there are others such as Podman (OCI-R),
Linux containers, Rocket, and Cloud Foundry.

Compared to virtual machines, containers are much smaller and faster to deploy and tear down.
The key advantage of containers is that they give precise control over the environment
in which an application executes ‚Äì which versions of tools, languages, libraries, and
packages. The isolation between containers allows for one application to be running
Python&nbsp;v3.9 and another using Python&nbsp;v3.10 on the same serverfootnote:[Of course
this is also possible using python virtual environments].

A second benefit of containers is that their contents and construction are described
in code, as a configuration file. This allows easy integration into a CI/CD workflow
for build, test and deployment.

Containers are frequently used for applications deployed on a cloud infrastructure. They
map particularly well with the notion of _micro-services_ where each specific function
runs in its own container ‚Äì for example in a typical three-tier application, the web-server,
application server (middleware), and database will each have their own container. This
allows for independent scaling of each of the components, for example, it is possible to
have two instances of the front-end web server if needed, without changing the anything
in the back-end.

Using Linux's resource constraints (`cgroups`), containers can be limited in the amount
of memory, CPU, network that they
consume, limiting the noisy neighbour effect to a degree. Containers can also help with
security, file systems can be mounted
as read-only and the kernel filesystem is always read-only. Podman (see below)
allows for non-root users to create and control their own containers.
This means that should a bad actor manage to break out of a container, the damage she/he
may inflict is considerably more limited that it would be were the container running with
root privilegesfootnote:[Docker allows this too, but it is rarely used in practice] and
unfettered write access to the file-system.

It's not all a bed of roses though, despite what you might hear the evangelists telling you.
Containers multiply the number of things that can go wrong and diagnosing the causes
is intrinsically more complicated with so many more moving pieces.
Network interfaces and storage devices breed like rabbits and they all have to be
managed. Also, because we never
occupy resources at 100%, we always leave some margin, the amount of unused and unusable
disk space tends to be greater when using containers and micro-services than when the same
application runs in a single OS instance. Each container has to be managed with updates,
backups and the usual lifecycle stuff.


=== Pods
Frequently any given service is made up of two or more closely related functions for which
it makes sense to deploy as as single unit. For this podman and kubernetes (see below)
introduce the notion of _pods_, a (small) number of containers treated as a single entity
(for deploy, start, stop, ...).


=== Container engines
The executable that runs in a container is known as an image. A container is a running
imagefootnote:[or an image that has run in the past - the command `podman ps --all` shows
both running and non-running containers]. Images are stored locally or
in an image repository which may be public or private. The most well-known public image
repository is https://hub.docker.com[Docker hub].

A container engines perform three key roles:

[horizontal]
Image construction:: Define the contents of an image and the steps required to build it.
Container and pod construction:: Configure containers and pods to run on a given system.
Runtime:: Services to control the container/pod lifecycle (start, stop, ...). The two
most common runtimes are `runc` and `crun`. `crun` is the more modern and faster of the two.

=== Container images
A container image comprises three elements:

* A directory tree containing all the software and libraries that make up your application.
The root of this tree becomes the root filesystem, _rootfs_, (under `/`) of the container.
* A JSON file describing the contents of the _rootfs_.
* A manifest, also in JSON format, that ties the image to one or more specific processor
architectures ‚Äì you cannot deploy an image built for IBM PowerPC on an ARM-based server.

These three elements are bundled into a standard UNIX tar file. This tar file is then generally
pushed to an image repository. Container systems such as podman or docker, then download and
unpack the image onto a host. Then, the container system can launch the container runtime
(`runc` or `crun` typically) which uses the JSON file to configure the host container and
launch in turn the application.


=== Podman vs Docker
The two most common container engines are podman and dockerfootnote:[Don't confuse docker the
tool with **D**ocker the company.].
Podman is a modern drop-in replacement for Docker. Arriving after docker it has benefitted
from all the lessons learnt and offers, in my view, several improvements over its
predecessor, these include:

Podman supports pods:: It's in the name, podman allows grouping of tightly coupled
containers into a single pod which is then managed as a unit.

Podman is a command, not a daemon:: This detail brings considerable benefits, especially
when upgrading the container runtime. Docker runs as a daemon and shutting docker down
requires that all the containers are shut down too. Podman, run on-demand as command, exits
once its operation is complete and the containers remain operational. Therefore updating
podman can take place without any interruption of service.
+
Podman follows the UNIX _fork/exec_ paradigm and as such a container is a child process of
podman belonging to the UID of the user that executed the command. Under docker, the
container is a child of the docker daemon (`containerd`) rather than the docker client.

Non-root user containers:: Ordinary, unprivileged users can create images and podman
containers. An ever-increasing number of companies are outlawing root access ‚Äì I don't
even have root access on my company laptopfootnote:[Which turns out to be a right royal
pain in the proverbial and a self-inflicted denial of service as it slows my productivity
by a significant factor.]
Docker's approach of putting users in the `docker` group is fraught with danger
as it allows for a simple escape out of a container into the host OS.

Podman plays nicely with _systemd_:: Much to the chagrin of many, _systemd_ has become
the standard Linux intialization mechanism.
Docker has traditionally resisted all attempts to integrate
with systemd, maintaining that only docker should control the container lifecycle.
Podman allows
* systemd to manage the lifecyle of containers
* containers to have their own systemd
* send systemd notifications
* socket activation in a container

Podman is compatible with kubernetes:: Podman can produce and read configuration files in
the format used by kubernetes which greatly simplifies migrating between the two and can
help when debugging kubernetes deployment problems.

The podman command line is a superset of that of docker ‚Äì¬†if you set `alias docker=podman` in
your `.zsh` or `.bashrc` file, then everything should continue to work as expected, otherwise it's
considered a bug by the podman teamfootnote:[Of course `docker --help` will now produce podman
help which may or may not come as a surprise].


The only way to come to grips with the technology is to install it on a machine and to kick the tyres.
The next section gives a quick run-down of podman operation.

=== Podman
==== Installation
The https:://podman.io[podman website] has all the details with https://podman.io/getting-started/installation[instructions on how to install
on MacOS and Linux] (or Windows if you don't know any better)

=== Images
https://hub.docker.com/search[Docker hub] and https://gallery.ecr.aws[Amazon] host a
multitude of container images. Some are
officially sanctioned, others are made available by developers of varying abilities, some
good, some less so. You can download any of these images and use it as-is or use as a base
for customization. Without creating an account at https://docker.com[Docker (the company)]
you are quickly rate limited. I tend to opt for Amazon.

For the the following discussion will use the official nginx image.

To run and connect to this image's shell, you can use the following command

[source, shell]
----
% podman run -it --rm public.ecr.aws/nginx/nginx:1-alpine-perl sh
----

The command line options are the following:

[horizontal]
-i:: Interactive, keep _stdin_ open.
-t:: Attach a pseudo terminal. This option is generally used for
a throw-away shell as in our example.
--rm:: Remove the container when it exits.
public.ecr.aws/nginx/nginx:1-alpine-perl:: The fully qualified name of the image to load.
sh:: The command to run. This is frequently optional as many containers have a default
executable. For nginx, without surprise, the default command is to run the http server.

Podman downloads the *nginx* image from docker hub (other imagage repositories can be configured)
in chunks (_blobs_) and saves it to a local cache. If you create a second container based on
the same image, the download step will be elided.

////
TODO:
Need the output of the podman run command here
Also with some basic shell commands - cat /etc/os-release, ps, ls -F / or tree /
////

==== Running the containerized application
In our first contact with podman containers you ran the zsh/bash shell. This is not the
application that the image builder had in mind. Here's how to run the nginx http server
as intended.

First create a directory to hold a html files and add a home page:

[source, shell]
----
% mkdir html
% cat <<EOF > html/index.html
<!DOCTYPE html>
<html lang="en">
<head>
  <title>My first containerized web server</title>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="author" content="Wrongways Skidmark">
  <sytle>
      :root {
          font-family: system-ui, ui-sans-serif, helvetica;
      }

      h1 {
          color: red;
          font-weight: 200;
      }
</head>
<body>
  <h1>This is my first containerized web page üèÜ</h1>
  <p>It'll be amazing üß® if it works first time</p>
</body>
</html>
EOF
----

Now you have a web page, you can add it to your containerized nginx application when
you launch it. Here's the command:

[source, shell]
----
% podman run -d \ # <1>
    --name  web_server \ # <2>
    -v "${PWD}/html":/usr/share/nginx/html:ro \ # <3>
    -p 8080:80 \ # <4>
    nginx # <5>
----

// TODO: Add terminal output

We no loner require an interactive session nor a terminal, so these option have been removed.
The container will not be automatically deleted when it exits either. The new options are:

<1> -d or `--detatch`, instructs podman to run the container in the background. The podman command
will exit, leaving the container running.
<2> --name ‚Äì give the container a custom name
<3> -v or --volume. Binds a directory on the host to a directory in the container. In this case
maps the directory *html* you just created on the host to the directory that nginx uses to
serve web pages. The *:ro* tag mounts the volume as read-only, so the container cannot modify
the files on the host.
<4> -p or `--publish`. Podman binds the container port (the second `8080`) to a host port (the first `8080`)
providing a bridge from the host to the container. It is custom to use the same port on the host and the
container where possible. Of course if you run a second instance of nginx, then the host's 8080 port
is already take so you have to specify a different one. i.e. -p 8081:8080.
<5> nginx ‚Äì the image to launch.

Now you can launch a browser on the host and connect to *http://localhost:8080/* and, if all goes to
plan, you should see the spectacular page we wrote earlier.


==== Stopping containers
Now you have a running container - how do you kill it? Without much surprise:

[source, shell]
----
% podman stop web_server
----
// TODO: Add terminal output

You can also use the first part of the container ID instead of the name - it has to be sufficiently long
to uniquely identify the container. By default podman will wait ten seconds for the container to
gracefully exit before using the nuclear option with `SIGKILL`. You can control the grace time with the
`-t` switch of the stop command.

==== Restarting containers
If you run `podman ps --all` (see below), you will see the *my_web_server* container, even though it is not running.
You can re-run the container with the same options as when you first launched it by simply typing:

[source, shell]
----
% podman start web_server
----

// TODO: Add terminal output

You can now reconnect your web browser with the web server.

The podman start command launches one or more containers, printing the container IDs. If you add the `-all`
switch, all stopped containers will be relaunched.

==== Listing containers
As hinted at above, you can list containers using the `podman ps`

// TODO: Add terminal output

Without any options this command lists only running containers. the `--all` switch adds halted ones too.

// TODO: Add terminal output

==== Container and image details
Podman has an inspect command to examine the details of containers and images.
The output is in JSON format, so it's handy to have the https://stedolan.github.io/jq/[*`jq`*] command installed -
*jq* is available as an installable package on most Linux distributions.

[source, shell]
----
podman inspect web_server | jq -C | less -R
----

[horizontal]
-C:: tells jq to use colour
-R:: tells less to pass-through raw colour characters

The top level structure is an array, with one element (index=0) containing a dictionary.
jq can select specific elements in the JSON. For example to get the command, which is in
the *Config* section with the key *Cmd* use:

[source, shell]
----
podman inspect web_server | jq '[0].Config.Cmd'
----

When printing to the terminal, jq uses colour by default, so we don't need the `-C` switch.

Alternatively, if you don't have *jq* installed you can use the clunky `--format` switch of the
podman inspect command:

[source, shell]
----
podman inspect web_server --format "Run command: {{.Config.Cmd}}"
----

You don't get any colour and you have to add your own text to identify each field. If you
ask for the whole *Config* entry you get a bunch of untagged fields:

[source, shell]
----
podman inspect web_server --format "Run command: {{.Config}}"
----

Compare this to:
[source, shell]
----
podman inspect web_server | jq '[0].Config'
----

In a similar way you can inspect images:

[source, shell]
----
podman image inspect image_id | image_name
----

Once again, *jq* is your friend to extract the stanzas you're interested in.

[source, shell]
----
podman image inspect 3374720 | jq '.[0].Size'
----

==== Deleting images
To remove an image you no longer require, freeing up disk space

[source, shell]
----
podman rmi <image-id | image-name>
----

Or alternatively, use prune which removes images that aren't currently used by a container

[source, shell]
----
podman image prune [-a]
----

NOTE: TODO: Output of `podman rmi <image-id | image-name>` and `podman image prune`


==== Podman commands
There is a plethora of additional podman commands. These are summarized in the table below. See
https://docs.podman.io/en/latest/Commands.html[the podman site] for details.

.Click here to see the full list of podman commands
[%collapsible]
====
[stripes=hover]
[frame=ends]
[width=80%]
[cols="2,9"]
[%header]
,====
include::podman_commands.csv[]
,====
====


=== Podman images
So far the images we've seen have been provided by a registry. But SEMS is an application with a custom
application. In this section we look at how you can build your own images.

We (almost) always start from a base image from a repository and customize its content and behaviour.
The base image might be just the base Linux operating system or it may include additional components
such as Node.js, a database, or programming languages (python, rust, ruby, clang, gcc).

Podman has a `build` command which invokes a tool called `buildah`

Images are built incrementally

NOTE: Need diagram with layered images: Linux -> + nginx -> my-app

To see the components of your image use the `podman image tree <image-name>` command and to see the differences
between two images use `podman image diff <img1> <img2> which lists files that have been added (A),
removed (D), and changed \(C).

NOTE: TODO Output of `podman image tree <image-name>`

NOTE: TODO Output of `podman image diff <img1> <img2>`

==== Building images
To construct the simplest way is to populate a file called either *Containerfile* or *Dockerfile*, the
latter to be able to compatible with docker. This file describes all the steps required to create
your image:

. identify the base image
. set environment variables
. install modules and packages
. run arbitary commands
. copy files from the host or the internet to the image
. establish the working directory
. stipulate the command to be run when the image is launched
. specify the username that will own the executable
. set tags and labels

This file is usually in the root directory of your application.

[source, shell]
----
% cat myapp/Containerfile
FROM
COPY index.html /usr/share/nginx/html/
----

With these files -- Containerfile and index.html -- in place you can build your image:

[source, shell]
----
% podman build ./myapp
----


// TODO: Add output


=== Kubernetes
k8s for the hip.
